{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee2f501",
   "metadata": {},
   "source": [
    "# LTSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74392ea190ca49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# 检查是否可以使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cc6f8621236eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将TF-IDF数据转换为PyTorch张量\n",
    "X_train_tensor = torch.tensor(X_train_vec2, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_val_vec2, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee4f706887c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建自定义数据集类\n",
    "class PhraseDataset(Dataset):\n",
    "    def __init__(self, features, labels=None):\n",
    "        self.features = features  # 特征数据\n",
    "        self.labels = labels  # 标签数据\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)  # 返回数据集的长度\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.features[idx], self.labels[idx]  # 返回特征和标签\n",
    "        else:\n",
    "            return self.features[idx]  # 只返回特征\n",
    "\n",
    "# 准备数据集\n",
    "train_labels = train['Sentiment'].values  # 获取训练集标签\n",
    "train_dataset = PhraseDataset(X_train_tensor, train_labels)  # 创建训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479327304cb48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# 将数据集拆分为训练集和验证集\n",
    "train_size = int(0.8 * len(train_dataset))  # 计算训练集大小\n",
    "val_size = len(train_dataset) - train_size  # 计算验证集大小\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])  # 拆分数据集\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)  # 创建训练数据加载器\n",
    "val_loader = DataLoader(val_subset, batch_size=32)  # 创建验证数据加载器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2234c6cc5c4dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义情感分类模型\n",
    "class SentimentNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)  # 第一个全连接层\n",
    "        self.fc2 = nn.Linear(64, 32)  # 第二个全连接层\n",
    "        self.fc3 = nn.Linear(32, output_size)  # 输出层\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout层，防止过拟合\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # 应用ReLU激活函数\n",
    "        x = self.dropout(x)  # 应用Dropout\n",
    "        x = F.relu(self.fc2(x))  # 应用ReLU激活函数\n",
    "        x = self.dropout(x)  # 应用Dropout\n",
    "        x = self.fc3(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "# 设置训练参数\n",
    "input_dim = X_train.shape[1]  # 输入维度\n",
    "output_size = 5  # 输出类别数\n",
    "net = SentimentNN(input_dim, output_size).to(device)  # 创建模型并移动到指定设备\n",
    "net.train()  # 设置模型为训练模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587312fb985f34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数\n",
    "epochs = 100  # 训练轮数\n",
    "lr = 0.001  # 学习率\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)  # 优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 损失函数\n",
    "\n",
    "# 早停设置\n",
    "best_val_acc = 0  # 最佳验证准确率\n",
    "patience = 10  # 早停耐心值\n",
    "counter = 0  # 早停计数器\n",
    "\n",
    "# 训练循环\n",
    "for e in range(epochs):\n",
    "    net.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0  # 记录训练损失\n",
    "    running_acc = 0.0  # 记录训练准确率\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # 将数据移动到指定设备\n",
    "\n",
    "        optimizer.zero_grad()  # 清零梯度\n",
    "        \n",
    "        output = net(inputs)  # 前向传播\n",
    "\n",
    "        loss = criterion(output, labels)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新权重\n",
    "\n",
    "        running_loss += loss.item()  # 累加损失\n",
    "        running_acc += (output.argmax(dim=1) == labels).float().mean()  # 累加准确率\n",
    "\n",
    "    print(f\"Epoch {e + 1}/{epochs}, Loss: {running_loss / len(train_loader):.6f}, Acc: {running_acc / len(train_loader):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0099127a42cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 验证阶段\n",
    "    net.eval()  # 设置模型为评估模式\n",
    "    val_loss = 0.0  # 记录验证损失\n",
    "    val_acc = 0.0  # 记录验证准确率\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)  # 将数据移动到指定设备\n",
    "            val_output = net(val_inputs)  # 前向传播\n",
    "            val_loss += criterion(val_output, val_labels).item()  # 累加损失\n",
    "            val_acc += (val_output.argmax(dim=1) == val_labels).float().mean().item()  # 累加准确率\n",
    "\n",
    "    val_acc /= len(val_loader)  # 计算平均验证准确率\n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.6f}, Validation Accuracy: {val_acc:.6f}\")\n",
    "\n",
    "    # 早停检查\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc  # 更新最佳验证准确率\n",
    "        counter = 0  # 重置早停计数器\n",
    "    else:\n",
    "        counter += 1  # 增加早停计数器\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")  # 触发早停\n",
    "            break\n",
    "\n",
    "# 测试集预测\n",
    "net.eval()  # 设置模型为评估模式\n",
    "test_predictions = []  # 存储测试集预测结果\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    test_loader = DataLoader(PhraseDataset(X_test_tensor), batch_size=32)  # 创建测试数据加载器\n",
    "    for test_inputs in test_loader:\n",
    "        test_inputs = test_inputs.to(device)  # 将数据移动到指定设备\n",
    "        test_output = net(test_inputs)  # 前向传播\n",
    "        test_predictions.extend(test_output.argmax(dim=1).cpu().numpy())  # 存储预测结果\n",
    "\n",
    "# 创建输出DataFrame，包含PhraseId和Sentiment\n",
    "output_df = pd.DataFrame({\n",
    "    'PhraseId': test['PhraseId'],  # 确保'PhraseId'对应于测试集中的正确列\n",
    "    'Sentiment': test_predictions\n",
    "})\n",
    "\n",
    "# 保存预测结果到CSV文件\n",
    "output_path = 'E:/shuju/answer/predictions.csv'\n",
    "\n",
    "# 如果输出目录不存在，则创建\n",
    "output_dir = os.path.dirname(output_path)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 保存预测结果\n",
    "output_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
